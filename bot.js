import express from 'express';
import { Telegraf } from 'telegraf';
import fetch from 'node-fetch';
import bodyParser from 'body-parser';

const app = express();
app.use(bodyParser.json());

const TELEGRAM_BOT_TOKEN = '7813374449:AAENBb8BN8_oD2QOSP31tKO6WjpS4f0Dt4g';
const HF_API_KEY = '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';
// const TELEGRAM_BOT_TOKEN = '';
const GEMINI_API_KEY = 'AIzaSyDc7u7wTVdDG3zP18xnELKs0HX7-hImkmc';
// const HF_API_KEY = 'YOUR_HUGGINGFACE_API_KEY';
const PORT = process.env.PORT || 3000;

const bot = new Telegraf(TELEGRAM_BOT_TOKEN);

// ğŸ Bot Start
bot.start((ctx) => ctx.reply(
    "ğŸ‘‹ Welcome to the AI Bot! Use these commands:\n\n" +
    "ğŸ“¸ /image <prompt> - Generate AI image\n" +
    "ğŸ­ /style <prompt> - Generate image in a specific style\n" +
    "ğŸ”„ /regen - Regenerate last image\n" +
    "ğŸ¨ /variants <prompt> - Generate multiple image versions\n" +
    "ğŸ” /upscale - Improve image quality\n" +
    "ğŸ’¬ /chat <message> - Chat with AI\n"
));


// ğŸ–¼ï¸ Generate AI Image (Advanced Features)
async function generateImage(prompt, style = "realistic", negativePrompt = "") {
    try {
        const response = await fetch('https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${HF_API_KEY}`
            },
            body: JSON.stringify({
                inputs: prompt,
                parameters: {
                    style,  // Different styles: 'realistic', 'anime', '3d', 'digital painting'
                    negative_prompt: negativePrompt, // Avoid unwanted elements
                    quality: 'high'
                }
            }),
        });

        if (!response.ok) throw new Error('Failed to generate image!');
        return await response.arrayBuffer();
    } catch (error) {
        console.error("Error:", error);
        return null;
    }
}

// ğŸ“¸ Image Generation Command
bot.command('image', async (ctx) => {
    const prompt = ctx.message.text.replace('/image ', '');
    if (!prompt) return ctx.reply("âŒ Please provide a prompt. Example: /image cyberpunk city");

    ctx.reply("ğŸ¨ Generating image... Please wait!");
    const image = await generateImage(prompt);
    if (image) await ctx.replyWithPhoto({ source: Buffer.from(image) });
    else ctx.reply("âŒ Image generation failed. Try again!");
});

// ğŸ­ Style-Based Image Generation
bot.command('style', async (ctx) => {
    const args = ctx.message.text.split(' ');
    const style = args[1];
    const prompt = args.slice(2).join(' ');

    if (!style || !prompt) return ctx.reply("âŒ Usage: /style <style> <prompt>\nExample: /style anime warrior with sword");

    ctx.reply(`ğŸ­ Generating ${style} style image...`);
    const image = await generateImage(prompt, style);
    if (image) await ctx.replyWithPhoto({ source: Buffer.from(image) });
    else ctx.reply("âŒ Failed to generate style image. Try again!");
});

// ğŸ”„ Regenerate Last Image
let lastPrompt = "";
bot.command('regen', async (ctx) => {
    if (!lastPrompt) return ctx.reply("âŒ No previous image found.");
    
    ctx.reply("ğŸ”„ Regenerating image...");
    const image = await generateImage(lastPrompt);
    if (image) await ctx.replyWithPhoto({ source: Buffer.from(image) });
    else ctx.reply("âŒ Regeneration failed. Try again!");
});

// ğŸ¨ Generate Multiple Variants
bot.command('variants', async (ctx) => {
    const prompt = ctx.message.text.replace('/variants ', '');
    if (!prompt) return ctx.reply("âŒ Please provide a prompt. Example: /variants futuristic city");

    ctx.reply("ğŸ–¼ï¸ Generating multiple variations... Please wait!");
    for (let i = 0; i < 3; i++) { // Generate 3 variations
        const image = await generateImage(prompt);
        if (image) await ctx.replyWithPhoto({ source: Buffer.from(image) });
    }
});

// ğŸ” Upscale Image (Placeholder)
bot.command('upscale', async (ctx) => {
    ctx.reply("ğŸ” Upscaling feature coming soon...");
});

// ğŸ’¬ AI Chat Using Gemini
async function chatWithGemini(message) {
    try {
        const response = await fetch(`https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateText?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt: message })
        });

        const data = await response.json();
        return data.candidates?.[0]?.output || "ğŸ¤– I couldn't understand. Try again!";
    } catch (error) {
        console.error("Chat AI Error:", error);
        return "âŒ Chat AI is not available now. Try again later!";
    }
}

// ğŸ”¹ AI Chat Command
bot.command('chat', async (ctx) => {
    const message = ctx.message.text.replace('/chat ', '');
    if (!message) return ctx.reply("ğŸ’¬ Please send a message. Example: /chat How are you?");

    ctx.reply("ğŸ¤– Thinking...");
    const reply = await chatWithGemini(message);
    ctx.reply(reply);
});

// âš¡ Keep Bot Alive (Bypass Render Shutdown)
setInterval(() => {
    fetch(`https://${process.env.RENDER_EXTERNAL_URL || 'https://imagicaaa-1.onrender.com'}`)
        .then(() => console.log("âœ… Keep-alive ping sent."))
        .catch(err => console.error("âŒ Keep-alive failed:", err));
}, 30000);

// ğŸš€ Start Bot
bot.launch();
console.log("ğŸš€ Bot started using long polling...");

// ğŸŒ Express Server for Render
app.get('/', (req, res) => res.send('ğŸ¤– AI Telegram Bot is Running...'));
app.listen(PORT, () => console.log(`ğŸš€ Server running on port ${PORT}`));
